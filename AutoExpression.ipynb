{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# æƒ…æ„Ÿåˆ†æä¹‹è¡¨æƒ…é€‚é…\n",
    "\n",
    "ä½¿ç”¨RNN + WordEmbeddingæ¥å»ºç«‹ä¸€ä¸ªè¡¨æƒ…é€‚é…å™¨ \n",
    "\n",
    "æˆ‘ä»¬ç»å¸¸å–œæ¬¢åœ¨æ–‡å­—åé¢åŠ ä¸Šè¡¨æƒ…æ¥ä½¿å¾—æˆ‘ä»¬çš„æ–‡å­—æ›´åŠ æœ‰è¡¨è¾¾æ€§å’Œæ„ŸæŸ“åŠ›ï¼Œä½†æ˜¯æ¯æ¬¡è¾“å…¥å®Œæ–‡å­—éƒ½éœ€è¦æˆ‘ä»¬èŠ±ä¸Šä¸€å®šçš„æ—¶é—´å»æŒ‘é€‰è¡¨æƒ…ã€‚è€Œæœ¬é¡¹ç›®çš„ç›®çš„åœ¨äºåœ¨ç”¨æˆ·è¾“å…¥å®Œæ–‡å­—ä¹‹åèƒ½å¤Ÿè‡ªåŠ¨é…ä¸Šç›¸åº”åœºæ™¯çš„è¡¨æƒ…ï¼Œä½¿å¾—è¯­å¥æ›´å…·æœ‰è¡¨è¾¾æ€§åŒæ—¶åˆèŠ‚çœäº†ç”¨æˆ·çš„æ—¶é—´ä¸ç²¾åŠ›ã€‚æ¯”å¦‚åœ¨æˆ‘ä»¬è¾“å®Œè¯­å¥ \"Congratulations on the promotion! Lets get coffee and talk. Love you!\"ä¹‹åï¼Œè¡¨æƒ…é€‚é…å™¨èƒ½å¤Ÿè‡ªåŠ¨åœ¨æ¯å¥è¯åæ·»åŠ ä¸Šè¡¨æƒ…ï¼Œå¦‚ï¼š \"Congratulations on the promotion! ğŸ‘ Lets get coffee and talk. â˜•ï¸ Love you! â¤ï¸\"\n",
    "\n",
    "æˆ‘ä»¬å°†å®Œæˆä¸€ä¸ªæ¨¡å‹ï¼Œåœ¨è¾“å…¥ä¸€ä¸ªå¥å­ï¼ˆå¦‚\"I want to play basketball!\"ï¼‰ä¹‹åï¼Œæ¨¡å‹å°†ä¼šæ‰¾åˆ°æœ€åŒ¹é…å½“å‰è¯­å¥çš„è¡¨æƒ…ï¼ˆâš¾ï¸ï¼‰åŠ åœ¨è¯­å¥çš„ç»“å°¾å¤„ã€‚åœ¨è®¸å¤šç°æœ‰çš„æ¨¡å‹ä¸­ï¼Œæ¨¡å‹å°†åªä¼šè®°å¾—â¤ï¸æ˜¯\"heart\"çš„æ ‡å¿—ï¼Œä½†å½“æ¢äº†ä¸€ä¸ªè¯ä¾‹å¦‚\"love\"çš„æ—¶å€™ï¼Œæ¨¡å‹å°†ä¸ä¼šè¯†åˆ«å‡ºã€‚è€Œåœ¨æœ¬é¡¹ç›®ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨è¯å‘é‡æ¥è¡¨å¾æ¯ä¸€ä¸ªå•è¯ï¼Œä½¿å¾—ç®—æ³•èƒ½å¤Ÿæ³›åŒ–åˆ°è®­ç»ƒé›†ä¸­æ²¡æœ‰å‡ºç°çš„è¯æ±‡ä¸­ï¼Œå¦‚è®­ç»ƒé›†ä¸­çš„â¤ï¸æ˜¯\"heart\"çš„æ ‡å¿—ï¼Œå½“æˆ‘ä»¬è¾“å…¥è®­ç»ƒé›†ä¸­æ²¡æœ‰çš„è¯æ±‡\"love\"æ—¶ï¼Œâ¤ï¸ä¹Ÿä¼šè¢«è‡ªåŠ¨æ·»åŠ ä¸Šã€‚å› æ­¤ï¼Œè¯å‘é‡çš„å¼•å…¥è¿˜å…è®¸æˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªè¾ƒå°çš„è®­ç»ƒé›†æ¥è®­ç»ƒæˆ‘ä»¬çš„æ¨¡å‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from expression_utils import *\n",
    "import emoji\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - æ•°æ®é¢„å¤„ç†\n",
    "\n",
    "### 1.1 - æ•°æ®é›† EMOJISET\n",
    "\n",
    "æˆ‘ä»¬æœ‰ä¸€ä¸ªè¾ƒå°çš„æ•°æ®é›†(X, Y)\n",
    "\n",
    "- X å«æœ‰127ä¸ªå¥å­ï¼ˆéƒ½æ˜¯å­—ç¬¦ä¸²ï¼‰\n",
    "- Y å«æœ‰ä¸€ä¸ªæ•´æ•°æ ‡ç­¾ï¼ˆ0-4ï¼‰åˆ†åˆ«å¯¹åº”æ¯ä¸ªå¥å­æ‰€é€‚ç”¨çš„è¡¨æƒ…\n",
    "\n",
    "<img src=\"images/data_set.png\" style=\"width:700px;height:300px;\">\n",
    "<caption><center> **Figure 1**: EMOJISET - ä¸€ä¸ªæœ‰ç€5ä¸ªç±»çš„åˆ†ç±»é—®é¢˜ï¼Œè¿™é‡Œç»™å‡ºäº†ä¸€äº›å¥å­çš„ä¾‹å­</center></caption>\n",
    "\n",
    "åˆ’åˆ†æ•°æ®é›†ä¸ºè®­ç»ƒé›†ï¼ˆ127ä¸ªä¾‹å­ï¼‰å’Œæµ‹è¯•é›†ï¼ˆ56ä¸ªä¾‹å­ï¼‰ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = read_csv('data/train.csv')\n",
    "X_test, Y_test = read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxLen = len(max(X_train, key=len).split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ‰“å°X_trainä¸­çš„æŸä¸ªå¥å­å’Œå¯¹åº”çš„æ ‡ç­¾ï¼Œindexå¯ä»¥è‡ªè¡Œæ”¹å˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love you mum â¤ï¸\n"
     ]
    }
   ],
   "source": [
    "index = 5\n",
    "print(X_train[index], label_to_emoji(Y_train[index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¸ºäº†ä½¿æ ‡ç­¾æ ¼å¼åŒ–ï¼Œä½¿ç”¨\"one-hot representation\"è½¬æ¢$Y$ä»ç»´åº¦$(m, 1)$åˆ° $(m, 5)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_oh_train = convert_to_one_hot(Y_train, C = 5)\n",
    "Y_oh_test = convert_to_one_hot(Y_test, C = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æŸ¥çœ‹è½¬æ¢åYæ ‡ç­¾çš„æ•ˆæœï¼Œindexå¯ä»¥è‡ªè¡Œæ”¹å˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 è½¬æ¢ä¸ºone hotå‘é‡ [1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "index = 5\n",
    "print(Y_train[index], \"è½¬æ¢ä¸ºone hotå‘é‡\", Y_oh_train[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "å°†è¾“å…¥å¥å­è½¬æ¢æˆè¯å‘é‡è¡¨å¾å½¢å¼ï¼Œæˆ‘ä»¬ä½¿ç”¨50ç»´çš„GloVe embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('data/GloveWordEmbedding.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç”Ÿæˆ3ä¸ªpythonå­—å…¸\n",
    "- `word_to_index`: å°†æ¯ä¸ªå•è¯æ˜ å°„ä¸ºä»–ä»¬åœ¨è¯æ±‡è¡¨æ‰€å¯¹åº”çš„ç´¢å¼•ï¼ˆè¯æ±‡è¡¨ä¸­å…±400001ä¸ªå•è¯ï¼Œå¯¹åº”ç€ç´¢å¼•0-400000ï¼‰\n",
    "- `index_to_word`: å°†æ¯ä¸ªç´¢å¼•æ˜ å°„ä¸ºä»–ä»¬åœ¨è¯æ±‡è¡¨æ‰€å¯¹åº”çš„å•è¯\n",
    "- `word_to_vec_map`: å°†æ¯ä¸ªå•è¯æ˜ å°„ä¸ºGloVeå‘é‡è¡¨å¾å½¢å¼\n",
    "\n",
    "æµ‹è¯•è½¬æ¢æ•ˆæœï¼Œindexå¯ä»¥è‡ªè¡Œæ”¹å˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cucumber åœ¨è¯æ±‡è¡¨ä¸­çš„ç´¢å¼•ä¸º 113317\n",
      "ç´¢å¼• 289846åœ¨è¯æ±‡è¡¨ä¸­å¯¹åº”çš„å•è¯æ˜¯ potatos\n"
     ]
    }
   ],
   "source": [
    "word = \"cucumber\"\n",
    "index = 289846\n",
    "print(word, \"åœ¨è¯æ±‡è¡¨ä¸­çš„ç´¢å¼•ä¸º\", word_to_index[word])\n",
    "print(\"ç´¢å¼•\", str(index) + \"åœ¨è¯æ±‡è¡¨ä¸­å¯¹åº”çš„å•è¯æ˜¯\", index_to_word[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - æ­å»ºç¥ç»ç½‘ç»œ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 - æ¨¡å‹1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 - æ¨¡å‹ç»“æ„\n",
    "<center>\n",
    "<img src=\"images/model1.png\" style=\"width:900px;height:300px;\">\n",
    "<caption><center> **Figure 2**: Average model.</center></caption>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_avg(sentence, word_to_vec_map):\n",
    "   \n",
    "    words = sentence.lower().split()\n",
    "\n",
    "    avg = np.zeros((50,))\n",
    "    \n",
    "    for w in words:\n",
    "        avg += word_to_vec_map[w]\n",
    "    avg = avg / len(words)\n",
    "    \n",
    "    return avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æµ‹è¯•æŸä¸ªå¥å­çš„å‡å€¼è¯å‘é‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg =  [-0.008005    0.56370833 -0.50427333  0.258865    0.55131103  0.03104983\n",
      " -0.21013718  0.16893933 -0.09590267  0.141784   -0.15708967  0.18525867\n",
      "  0.6495785   0.38371117  0.21102167  0.11301667  0.02613967  0.26037767\n",
      "  0.05820667 -0.01578167 -0.12078833 -0.02471267  0.4128455   0.5152061\n",
      "  0.38756167 -0.898661   -0.535145    0.33501167  0.68806933 -0.2156265\n",
      "  1.797155    0.10476933 -0.36775333  0.750785    0.10282583  0.348925\n",
      " -0.27262833  0.66768    -0.10706167 -0.283635    0.59580117  0.28747333\n",
      " -0.3366635   0.23393817  0.34349183  0.178405    0.1166155  -0.076433\n",
      "  0.1445417   0.09808667]\n"
     ]
    }
   ],
   "source": [
    "avg = sentence_to_avg(\"Morrocan couscous is my favorite dish\", word_to_vec_map)\n",
    "print(\"avg = \", avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 - å»ºç«‹æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, Y, word_to_vec_map, learning_rate = 0.01, num_iterations = 400):\n",
    "    \n",
    "    np.random.seed(1)\n",
    "\n",
    "    m = Y.shape[0]                          # number of training examples\n",
    "    n_y = 5                                 # number of classes  \n",
    "    n_h = 50                                # dimensions of the GloVe vectors \n",
    "    \n",
    "    # Initialize parameters using Xavier initialization\n",
    "    W = np.random.randn(n_y, n_h) / np.sqrt(n_h)\n",
    "    b = np.zeros((n_y,))\n",
    "    \n",
    "    # Convert Y to Y_onehot with n_y classes\n",
    "    Y_oh = convert_to_one_hot(Y, C = n_y) \n",
    "    \n",
    "    # Optimization loop\n",
    "    for t in range(num_iterations):                       # Loop over the number of iterations\n",
    "        for i in range(m):                                # Loop over the training examples\n",
    "            \n",
    "            # Average the word vectors of the words from the i'th training example\n",
    "            avg = sentence_to_avg(X[i], word_to_vec_map)\n",
    "\n",
    "            # Forward propagate the avg through the softmax layer\n",
    "            z = W @ avg + b\n",
    "            a = softmax(z)\n",
    "\n",
    "            # Compute cost using the i'th training label's one hot representation and \"A\" (the output of the softmax)\n",
    "            cost = -np.sum(Y_oh[i] * np.log(a))\n",
    "            \n",
    "            # Compute gradients \n",
    "            dz = a - Y_oh[i]\n",
    "            dW = np.dot(dz.reshape(n_y,1), avg.reshape(1, n_h))\n",
    "            db = dz\n",
    "\n",
    "            # Update parameters with Stochastic Gradient Descent\n",
    "            W = W - learning_rate * dW\n",
    "            b = b - learning_rate * db\n",
    "        \n",
    "        if t % 100 == 0:\n",
    "            print(\"Epoch: \" + str(t) + \" --- cost = \" + str(cost))\n",
    "            pred = predict(X, Y, W, b, word_to_vec_map)\n",
    "\n",
    "    return pred, W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132,)\n",
      "(132,)\n",
      "(132, 5)\n",
      "never talk to me again\n",
      "<class 'numpy.ndarray'>\n",
      "(20,)\n",
      "(20,)\n",
      "(132, 5)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(np.eye(5)[Y_train.reshape(-1)].shape)\n",
    "print(X_train[0])\n",
    "print(type(X_train))\n",
    "Y = np.asarray([5,0,0,5, 4, 4, 4, 6, 6, 4, 1, 1, 5, 6, 6, 3, 6, 3, 4, 4])\n",
    "print(Y.shape)\n",
    "\n",
    "X = np.asarray(['I am going to the bar tonight', 'I love you', 'miss you my dear',\n",
    " 'Lets go party and drinks','Congrats on the new job','Congratulations',\n",
    " 'I am so happy for you', 'Why are you feeling bad', 'What is wrong with you',\n",
    " 'You totally deserve this prize', 'Let us go play football',\n",
    " 'Are you down for football this afternoon', 'Work hard play harder',\n",
    " 'It is suprising how people can be dumb sometimes',\n",
    " 'I am very disappointed','It is the best day in my life',\n",
    " 'I think I will end up alone','My life is so boring','Good job',\n",
    " 'Great so awesome'])\n",
    "\n",
    "print(X.shape)\n",
    "print(np.eye(5)[Y_train.reshape(-1)].shape)\n",
    "print(type(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 --- cost = 1.9520498812810072\n",
      "Accuracy: 0.3484848484848485\n",
      "Epoch: 100 --- cost = 0.07971818726014807\n",
      "Accuracy: 0.9318181818181818\n",
      "Epoch: 200 --- cost = 0.04456369243681402\n",
      "Accuracy: 0.9545454545454546\n",
      "Epoch: 300 --- cost = 0.03432267378786059\n",
      "Accuracy: 0.9696969696969697\n",
      "[[3.]\n",
      " [2.]\n",
      " [3.]\n",
      " [0.]\n",
      " [4.]\n",
      " [0.]\n",
      " [3.]\n",
      " [2.]\n",
      " [3.]\n",
      " [1.]\n",
      " [3.]\n",
      " [3.]\n",
      " [1.]\n",
      " [3.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [3.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [4.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [0.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [0.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [3.]\n",
      " [0.]\n",
      " [3.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [0.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [0.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [3.]\n",
      " [3.]\n",
      " [1.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [3.]\n",
      " [2.]\n",
      " [4.]\n",
      " [0.]\n",
      " [0.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [2.]\n",
      " [0.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [1.]\n",
      " [1.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [1.]\n",
      " [2.]\n",
      " [1.]\n",
      " [1.]\n",
      " [3.]\n",
      " [1.]\n",
      " [0.]\n",
      " [4.]\n",
      " [0.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [3.]\n",
      " [0.]\n",
      " [2.]]\n"
     ]
    }
   ],
   "source": [
    "pred, W, b = model(X_train, Y_train, word_to_vec_map)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 - æµ‹è¯•æ€§èƒ½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "Accuracy: 0.9772727272727273\n",
      "Test set:\n",
      "Accuracy: 0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set:\")\n",
    "pred_train = predict(X_train, Y_train, W, b, word_to_vec_map)\n",
    "print('Test set:')\n",
    "pred_test = predict(X_test, Y_test, W, b, word_to_vec_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8333333333333334\n",
      "\n",
      "i adore you â¤ï¸\n",
      "i love you â¤ï¸\n",
      "funny lol ğŸ˜„\n",
      "lets play with a ball âš¾\n",
      "food is ready ğŸ´\n",
      "not feeling happy ğŸ˜„\n"
     ]
    }
   ],
   "source": [
    "X_my_sentences = np.array([\"i adore you\", \"i love you\", \"funny lol\", \"lets play with a ball\", \"food is ready\", \"not feeling happy\"])\n",
    "Y_my_labels = np.array([[0], [0], [2], [1], [4],[3]])\n",
    "\n",
    "pred = predict(X_my_sentences, Y_my_labels , W, b, word_to_vec_map)\n",
    "print_predictions(X_my_sentences, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¯¥ç®—æ³•æœ‰ä¸€ä¸ªå¾ˆå¤§çš„ç¼ºé™·ï¼Œå®ƒå¹¶æ²¡æœ‰ä½¿å¾—â€œnot feeling happyâ€æ­£ç¡®ã€‚ è¯¥ç®—æ³•å¿½ç•¥äº†å•è¯æ’åºï¼Œå› æ­¤ä¸å–„äºç†è§£â€œä¸å¼€å¿ƒâ€è¿™æ ·çš„çŸ­è¯­ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ‰“å°æ··æ·†çŸ©é˜µè¿˜æœ‰åŠ©äºäº†è§£å“ªäº›ç±»å¯¹äºæ¨¡å‹ç†è§£æ›´åŠ å›°éš¾ã€‚ æ··æ·†çŸ©é˜µæ˜¾ç¤ºäº†æ ‡ç­¾æ˜¯ä¸€ä¸ªç±»ï¼ˆâ€œå®é™…â€ç±»ï¼‰çš„ç¤ºä¾‹ç»å¸¸è¢«å…·æœ‰ä¸åŒç±»ï¼ˆâ€œé¢„æµ‹â€ç±»ï¼‰çš„ç®—æ³•é”™è¯¯æ ‡è®°çš„é¢‘ç‡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56,)\n",
      "           â¤ï¸    âš¾    ğŸ˜„    ğŸ˜   ğŸ´\n",
      "Predicted  0.0  1.0  2.0  3.0  4.0  All\n",
      "Actual                                 \n",
      "0            6    0    0    1    0    7\n",
      "1            0    8    0    0    0    8\n",
      "2            2    0   16    0    0   18\n",
      "3            1    1    2   12    0   16\n",
      "4            0    0    1    0    6    7\n",
      "All          9    9   19   13    6   56\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQwAAAD3CAYAAADormr9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAGPlJREFUeJzt3Xu4ZFV95vHve/pGk24Gmm4Q6BZ6BLmEUUDS8ZGJwyUSQIIIJrEzOIjMA8ZhBkQjyFxCniSD0QQdEok2iqLIxaAIGkAJoQUMt25guDWkO4ihsbk0SLiE7p6Gd/7Y+0Bxci67zqldteuc9/M89Zzau3bt36o6Vb9ae62915JtIiKqGOh1ASKifyRhRERlSRgRUVkSRkRUloQREZUlYUREZUkYEVFZEkZEVJaEERGVTe91AeokaR9gI4DtVT0qw4DtV7sQZwkwA9hs+/a647XE7cl73Iu4kuQpfmr0pK1hSDoc+D7wMeCvJZ3QpbjvlfSHks6RtG2XksVvAFcD7wUulXSKpDldiNur97gncYGZZfyufG8kuY3bdd0oE7Yn1Q0QMAe4BjiqXPdOYA3w0Zpj/yrwU+B3gS8BPwHeBcyo8bXOAr4O/Ha5bh/geuCTwOzJ9B73+H+7G3AFsHO5PFBnvDJG5YQBrKi7PLYnXw3DhReBFcBWkmbYvg34IHCGpONrDL838CPbl9j+KPAd4FPAftD5X6bytW4EVgFvkzTH9j3AacARwEc6GW9I3K6/xz3+3z4B/Aw4R9Ii2692o6YhqdKtWyZdwmjxBHAIMBvA9grgQ8B/lbS4pph3ArMl7VHGPBe4BfiCpK1d3+HJvcC2wFskTbf9APD7wOmS3l5TTOjNe9zVuJL+naQrbb8AnA08Cvx5t5JGEkbNVL57ts8HtgS+JOnflL9Gt1B8uepquHoC2Ay8R9L8shx/BtwPnFxTTGxfC7wInArsXdY0VgLXUVTj64rb1fdY0rQexH2U4tDg8jJpnENxCFR70pDEwMBApVu3qDxW6muSdgfmUVRVX7X9SstjlwEvA7dR9AqdDvwH22s7FHvakHj7An9M8WVdbvs+SWeW5fpsB+LtCmwN3G97w5DHPgvMBTYAjwGfAA6w/WgH4v4yMB9YZfup1h6DOt9jSf8eWGz7m+XyTNubuhD3TbafKO/PAr4GzLJ9rKS5wKeBXYCzOvH+DmdgYMAzZsyotO2mTZtW2t6/jnK06vuEIekY4H8Dj5e3FcDXbT/fss1HgB2BtwNnl1X2icZ9q+1/KO9Ps/3K4JeoTBonU3yxDSwBjrZ93wRjHknxWp+hqM38ie37y1/Y/1ducxDwNuCtwBdtPziRmOU+Dwf+FHiEouv2JNuPD4nb0fe4/NXeEridopZ0nu0vlY9tMZgsa/rf7gE8CPwf4EHbF0j6JeALwALbR5dJ44+ArSjej80TjTvUwMCAZ86cWWnbjRs3JmGMRdIM4GKKD9NPJB1L0Wq+Efic7X8esv2sspFwonGPBL4NfM/275brBpPGQFlNnQ9sA/wKcKvtn04w5ruAC4Gltu+WdD6whe2PlI+/4XyPsi1jwh9iSQcCy4DjbN8h6UqKRPS3Q2tX5fYdeY9b9vcp4BWKhHC37c+PsF3H4kpaBFxG0VV9CLAOuJzi0PLjwJvLmsZWFLWOpzsRd6iBgQHPmjWr0rYbNmzoSsKYDG0YW1F0eQFcCfyAor98KRQnNEnar3x800SDlb80p1D0RGySdDFAmSymt3xpN9teXfaYTChZtPiM7bvL+38AzCury5RJ6lfKZAbFl6wTngROLpPFmyi6jk+R9GWKhkYkvaOT7/EQm4FFwEXAEknnSjqnjPuuOuLafgy4g6J36wiKw8uTgG8AXwEWSTrP9vN1JYtBafTsoLI6fC5wjKRfK7+stwD3AO+WNBs4APh5uf2Eq1O2X6LorryE4lyHLVqSxmaAsmfiOElbqHP/zduB75b7n0Zx/sXOFAkTSQuBPSgOyTryWsv9rLJ9Y7l4InC+7aMp2g2OkLQL8G46+B4PcRXwhO0bKF7b71Ec6kFRe+to3Jb/1xkUh5PzKWoYbwdWA/+LotHz/E7EG6MsjUsYfX1IAsXxLPCfKY7bL7Z9U7l+OXCi7X+sOf62FFX2l20fJ+ltFDWem20/VVPM6cAWwFW2D5F0HLAvxTH8C3XEHKEc1wKnDrbl1BRjR+BPgL+nOKflmxRtQpcAl9aQoAaTxkzgfwL/lqKmcabt70naDVhv+xedjjvUtGnTPHv27ErbvvTSS105JOn7a0lsb5D0LYpfg0+XDVYbgQUUXY11x39G0snA5yQ9TFFre3ddyaKMuRl4UdJjZfX8UOCEOpNFa69IuXwssB1Qa4Ky/XNJj1F8ef+L7e+XDbtr6kgWZUwDGyV9E7gZ+Avb3ysfW11HzJF0s8u0ir5PGAC2fyHpAoqW7ZMpuhWPs/1kl+Kvl3QvcDjwHtvr6oxX/gLOAH6t/HtI3R/kli7UWcBxFF2Yv1P3ay1dQFGbWlku/9hduEbH9sOSzgB2lrSl7X+pO+ZQ3TzcqGJSJAyAsm/+Rkk3FYv1f6AGSdqGonHs0Il2nVZRfnk3Sfoj4M4u/+q9SnFMf4zth7sRsGyEfGywltPN/y1wK3BMF+O9ptvtE1X0fRtGU7SeG9DFmFP+cutu6FXtYvr06Z47d26lbZ977rm0YfSTbieLMmaSRRf0IlkMaloNIwkjosGSMCKisiSMiKhE5dWqTdKs0tRA0klTIWbiTs64TTvTc9InDIprAKZCzMSdhHE7mTAkPSrpPkn3SFpRrpsn6XpJq8u/24y2j6mQMCL6Vg01jINs79PSBXsmcIPt3YAbyuWRy9MPPXPz5s3zokWLxvXcZ555hm233XZcz606eMlQTz/9NAsWLBjXcydiInEn8jlYv3498+fPH9dzJ1Kdnsjr3bRp/Be3jvcztXbtWp599tnKL3jmzJmu+r6uW7duzPMwJD0K7G97fcu6h4EDba+TtAPFoE+7j7SPvmj0XLRoEddcc03X4+60005dj9krmzd3fPyXSqZP781H8NFHH+16zKOOOqrt53S4fcLAj1SMMv5l28uA7QdP7y+Txnaj7aAvEkbEVNVGwpg/2C5RWlYmhFYHlBfzbQdcL+mhdsuThBHRYG10q64f65DE9uDYIU+pGDltCfCkpB1aDklGvco6jZ4RDdXJAXQk/ZKKcUgHR407lGLIwauBwflcjqcYsGhEqWFENFgH2zC2B64s9zcduMT2dZLuBL4t6UTgn4DfGm0nSRgRDdaphGH7EYphBoeuf4ZioONKkjAiGizXkkREZUkYEVFJEy8+S8KIaLCm1TB6kr4kHSbpYUlrVMw7GhHDmPJXq6qYhOeLFCNs7wUslbRXt8sR0Q+mfMKgOLtsje1HypG+LwPe14NyRDRaJ0/c6pReJIydgMdalteW6yJiiKYljF40eg736v7VtdXlqEYnwdS6ajSiVRo9ixpF6+AWCykn1G1le5nt/W3vP97xLCL63cDAQKVb18rTtUivuxPYTdJiSTOBD1JcABMRLZrYhtH1QxLbmyWdAvwQmAZcaPuBbpcjoh807ZCkJydu2b4G6P4QWhF9JgkjIipLwoiIypIwIqKSbjdoVpGEEdFguVo1IipLDSMiKkvCiIhK0oYREW1JwoiIypIwxmHGjBk9uWJ1zZo1XY8JsOuuu3Y9Zq/mOO2VXswlO54Jr5MwIqKSDAIcEW1JDSMiKkvCiIjKkjAiorIkjIioJCduRURbmpYwmtVnExFv0MlBgCVNk3S3pB+Uy4sl3S5ptaTLyzF2Ry/PBF9PRNSow4MAnwqsaln+U+DztncDfgGcONYOkjAiGqqTo4ZLWgi8F/hKuSzgYOCKcpOLgKPH2k/aMCIarINtGF8APgXMLZe3BZ6zPXiOfKUZCHs1e/uFkp6SdH8v4kf0izZqGPMlrWi5ndSyjyOBp2yvbN31MOHGvNilVzWMrwN/CXyjR/Ej+kIbNYz1tvcf4bEDgKMkHQFsAWxFUePYWtL0spYx7AyEQ/WkhmH7JuDZXsSO6BeDF59NtJfE9qdtL7S9C8VMg39n+z8CNwIfKDc7HrhqrDKl0TOiwWqeKvEM4HRJayjaNL461hMa2+jZOnv7m9/85h6XJqI3On3ilu3lwPLy/iPAknae39gaRuvs7QsWLOh1cSJ6YspPxhwR1eXUcEDSpcCtwO6S1koa8wyziKmmkydudUqvZm9f2ou4Ef2maTWMHJJENFjG9IyISjIeRkS0JQkjIipLwoiIypIwIqKyJIyIqCSNnhHRlnSrRkRlqWGMw6uvvsrLL7/c9bi9mEUd4Nprr+16zMMPP7zrMXvp3nvv7XrM8XyGkzAiopK0YUREW5IwIqKyJIyIqCwJIyIqGRwEuEmSMCIaLDWMiKgsCSMiKkvCiIjKkjAiopImnrjV9SZYSYsk3ShplaQHJJ3a7TJE9IuMGg6bgU/YvkvSXGClpOttP9iDskQ02pTvVrW9DlhX3n9B0ipgJyAJI2KIph2S9LQNQ9IuwL7A7b0sR0QTNbENo2cJQ9Ic4DvAabafH+bx1yZjXrRoUZdLF9EMTUsYvZoqcQZFsviW7e8Ot03rZMzz58/vbgEjGqJvGj0lfR/wSI/bPmo8AVW8uq8Cq2yfO559REwVTathjHZI8mc1xTwA+BBwn6R7ynVn2b6mpngRfalTF59J2gK4CZhF8Z2/wvYfSFoMXAbMA+4CPmR702j7GjFh2P7xhEs6/H5vAZqVNiMaqkM1jI3AwbZfLJsDbpF0LXA68Hnbl0n6EnAi8Fej7WjM9CVpN0lXSHpQ0iODt068iogYXSfaMFx4sVycUd4MHAxcUa6/CDh6rPJUqe98jSLrbAYOAr4BfLPC8yJigjrV6ClpWtkE8BRwPfCPwHO2N5ebrKU4H2pUVRLGbNs3ALL9M9tnU2SmiKhZGwljvqQVLbeTWvdj+xXb+wALgSXAnsOEG7GTY1CV8zA2SBoAVks6BXgc2K7C8yJiAtrsMl1ve/+xNrL9nKTlwDuBrSVNL2sZC4Gfj/X8KjWM04Atgf8GvIOih+P4Cs+LiAnqxCGJpAWSti7vzwZ+HVgF3Ah8oNzseOCqscozZg3D9p3l3ReBE8baPiI6p0MXn+0AXCRpGkUl4du2fyDpQeAySX8M3E1xftSoxkwYkm5kmGMb22nHiKhZJ7pVbd9Lcc3W0PWPULRnVFalDeOTLfe3AI6l6DGJiBr15cVntlcOWfUTSbWc1BURb9R3CUPSvJbFAYqGzzfVVqLhy8CMGTO6GRKAzZt7U5E68MADux7zjjvu6HpMgCVL2qoRd8zs2bO7HnM8X/6+SxjASoo2DFEcivyU4hTSiKhZPyaMPW1vaF0haVZN5YmIFk1LGFX6bP5+mHW3drogEfFGg1erVrl1y2jjYbyJ4tzy2ZL25fUrTLeiOJErImrWtBrGaIckvwF8mOKU0T/n9YTxPHBWvcWKCOijhGH7Ioqzw461/Z0ulikiSk1LGFUOft4xeB46gKRtylNJI6JGVa8j6WZSqZIwDrf93OCC7V8AR9RXpIgY1LSEUaVbdZqkWbY3wmtXu6VbNaILmnZIUiVhXAzcIOlr5fIJFMN5RUTN+m6qRNuflXQvxTX0Aq4Ddq67YBFTXV9efFZ6AngV+G2KU8PH3Wsy0pDn491fxGTWNwlD0luBDwJLgWeAyynG9TxogjGHHfLc9m0T3G/EpNM3CQN4CLgZ+E3bawAkfXyiAW2bYvQueOOQ5xExRNMSxmgtKsdSHIrcKOkCSYfQoQmIhg55bjuzt0cMo2ndqiMmDNtX2v4dYA9gOfBxYHtJfyXp0IkEHTrkuaS9h24j6aTBIdPXr18/kXARfakvT9yy/ZLtb9k+kuILfg9wZieClyeELQcOG+axzN4eU17TrlZtK5LtZ21/eSIDAI8w5PlD491fxGTWtBpG1W7VThp2yPMelCOi8ZrW6Nn1hDHSkOcR8Ub9fOJWRPRAEkZEVJaEERGV9d3FZxHRG2nDiIi2JGFERGVJGBFRWRJGRFTWtITRrCbYiHhNpy4+k7RI0o2SVkl6QNKp5fp5kq6XtLr8u81YZeqLGoYkpk/vi6L2rV7Nov7444/3JO6ee+7Z9ZjjmTG+Q92qm4FP2L5L0lxgpaTrKSYqu8H2ZySdSXFR6RmjlqcTpYmIenSihmF7ne27yvsvAKsopkF9H68P6H0RcPRY5cnPdkRD1XEehqRdKK7luh3Y3vY6KJKKpO3Gen4SRkSDtZEw5kta0bK8zPayIfuaQzGA92m2nx9PMkrCiGiwNr7U623vP8p+ZlAki2/Z/m65+klJO5S1ix0ohswcVdowIhqsQ70kAr4KrLJ9bstDVwPHl/ePB64aqzypYUQ0WIfaMA4APgTcVw6+DXAW8Bng25JOBP4J+K2xdpSEEdFQkjrSrWr7FkYe8f+QdvaVhBHRYE070zMJI6LBkjAiorIkjIiopIkD6PSsW7WcLvFuSZliIGIEmZfkdadSnNO+VQ/LENFoqWEAkhYC7wW+0ov4Ef2iaVMl9qqG8QXgU8DcHsWPaLy0YQCSjgSesr1yjO1em7396aef7lLpIpqlaW0YvTgkOQA4StKjwGXAwZIuHrpR6+ztCxYs6HYZIxphyicM25+2vdD2LsAHgb+zfVy3yxHRD5qWMHIeRkSDNa0No6cJw/ZyYHkvyxDRVE1s9EwNI6LBMrdqRFSWGkZEVJaEERGVpA0jItqShBERlSVhRERl6SWJiErShhERbUnCGIcNGzawatWqXheja+67776ux9xxxx27HhNg8eLFUypuu5IwIqKyJIyIqCwJIyIqSaNnRLQl3aoRUVlqGBFRWRJGRFSSNoyIaEvTEkazWlQi4g06NQiwpAslPSXp/pZ18yRdL2l1+XebsfaThBHRYB0cNfzrwGFD1p0J3GB7N+CGcnlUSRgRDSWpY1Ml2r4JeHbI6vcBF5X3LwKOHms/tSYMSe+XZEl7lMu7DFaJJB2YmdsjRlfzvCTb214HUP7dbqwn1F3DWArcQjFhUUS0qY2EMX9watHydlId5amtl0TSHIppEQ8CrgbOritWxGTVRu1hve3929z9k5J2sL1O0g7AU2M9oc4axtHAdbb/AXhW0n41xoqYlGo+JLkaOL68fzxw1VhPqDNhLKWYbJny79J2nqyW2duffXZoW03E5Fc1WVTsVr0UuBXYXdJaSScCnwHeI2k18J5yeVS1HJJI2hY4GNhbkoFpgIHzq+7D9jJgGcDee+/tOsoZ0XSdOnHL9kg/2Ie0s5+62jA+AHzD9smDKyT9GFhYU7yISalpV6vWVZqlwJVD1n0HOKumeBGTUs1tGG2rpYZh+8Bh1p0HnNeyvJzM3B4xolx8FhFtScKIiMqSMCKisiSMiKgsCSMiKhm8WrVJkjAiGiw1jIioLAkjIipLwoiISnLi1jg98MAD6/faa6+fjfPp84H1nSxPQ2MmbvPj7tzuE5IwxsH2gvE+V9KKcQwsMiG9iJm4kzNuEkZEVJZu1YioJG0YvbFsisRM3EkYt2kJo1n1nRqUI3dNipiSXpF0j6T7Jf21pC3HG7d1mgdJR0kacRIbSVtL+thIj48UV9LZkj5ZtUzt6sX/tttxmzYexqRPGJPMy7b3sb03sAn4aOuDKrT9P7V9te3RxnPcGhgxYUR9kjCiU24GdlUxOdQqSecDdwGLJB0q6VZJd5U1kTkAkg6T9JCkW4BjBnck6cOS/rK8v72kKyX93/L2LorBYd9S1m4+V273+5LulHSvpD9s2dd/l/SwpL8Fdu/auzFJNS1hTIU2jElH0nTgcOC6ctXuwAm2PyZpPvA/gF+3/ZKkM4DTJX0WuIBicOY1wOUj7P484Me23y9pGjCHYs7NvW3vU8Y/FNgNWAIIuFrSu4GXKCat2pfis3UXsLKzr37qyMVnMVGzJd1T3r8Z+CqwI/Az27eV698J7AX8pPzlmUkxvPwewE9trwaQdDEw3OxYBwP/CcD2K8A/61/P6n1oebu7XJ5DkUDmAlfa/pcyxtUTerXRuEbPJIz+8vLgr/yg8gP1Uusq4Pqhw8pL2odiqodOEHCO7S8PiXFaB2MEzUsYzarvRCfcBhwgaVcASVtKeivwELBY0lvK7Uaap+IG4PfK506TtBXwAkXtYdAPgY+0tI3sJGk74Cbg/ZJmS5oL/GaHX9uUUrX9Io2eMW62nwY+DFwq6V6KBLKH7Q0UhyB/UzZ6jnRtzqnAQZLuo2h/+GXbz1Ac4twv6XO2fwRcAtxabncFMNf2XRRtI/dQTCtxc20vdIpoWsKQnRpkRBPtt99+vvnmajl3zpw5K7txfUvaMCIarGltGEkYEQ2VbtWIaEtqGBFRWRJGRFTWtITRrAOkiHiDTnWrltcRPSxpjUa5MnksSRgRDdWpE7fKa4K+SHH90V7AUkl7jadMSRgRDdahGsYSYI3tR2xvAi4D3jee8qQNI6LBOtStuhPwWMvyWuBXx7OjJIyIhlq5cuUPy+EKqthC0oqW5WUtI4MNVwUZ1yneSRgRDWX7sA7tai2wqGV5IfDz8ewobRgRk9+dwG6SFkuaSTHI0bjGKkkNI2KSs71Z0ikUwxJMAy60/cB49pWrVSOishySRERlSRgRUVkSRkRUloQREZUlYUREZUkYEVFZEkZEVJaEERGV/X/OSvtg/TTzpgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(Y_test.shape)\n",
    "print('           '+ label_to_emoji(0)+ '    ' + label_to_emoji(1) + '    ' +  label_to_emoji(2)+ '    ' + label_to_emoji(3)+'   ' + label_to_emoji(4))\n",
    "print(pd.crosstab(Y_test, pred_test.reshape(56,), rownames=['Actual'], colnames=['Predicted'], margins=True))\n",
    "plot_confusion_matrix(Y_test, pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 - æ¨¡å‹2 \n",
    "### ä½¿ç”¨Kerasæ¡†æ¶å»ºç«‹LSTMså•å…ƒï¼š\n",
    "ä½¿ç”¨é¢„è®­ç»ƒçš„æ¬¡åµŒå…¥è¡¨å¾æ¯ä¸ªå•è¯ï¼Œç„¶åå–‚ç»™LSTMå•å…ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.initializers import glorot_uniform\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 - æ¨¡å‹ç»“æ„\n",
    "\n",
    "<img src=\"images/model2.png\" style=\"width:700px;height:400px;\"> <br>\n",
    "<caption><center> **Figure 3**: 2å±‚LSTMåºåˆ—åˆ†ç±»å™¨. </center></caption>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 å¡«å……è®­ç»ƒé›†è¯­å¥\n",
    "\n",
    "å¯¹äºä¸€ä¸ªé€‰å®šçš„æ·±åº¦ç¥ç»ç½‘ç»œï¼Œæˆ‘ä»¬éœ€è¦æ¯ä¸ªè¾“å…¥çš„è¯­å¥æœ‰ç€ç›¸åŒçš„é•¿åº¦ï¼Œå³æœ‰ç›¸åŒæ•°é‡çš„å•è¯ã€‚ä½†æ˜¯ç°åœ¨è®­ç»ƒé›†ä¸­çš„å¥å­é•¿åº¦ä¸ä¸€ï¼Œæ‰€ä»¥æˆ‘ä»¬ä½¿ç”¨paddingæ¥å¡«å……æ¯ä¸ªå¥å­ã€‚ä½¿ç”¨è®­ç»ƒé›†æ‰€æœ‰å¥å­ä¸­æœ€é•¿çš„å¥å­çš„é•¿åº¦ä½œä¸ºè¾“å…¥RNNçš„è¯­å¥é•¿åº¦ï¼Œé•¿åº¦ä½äºæœ€é•¿é•¿åº¦çš„å¥å­ä¸­å‰©ä½™è¯å‘é‡å°±ç”¨é›¶å‘é‡è¿›è¡Œå¡«å……ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 - Embeddingå±‚\n",
    "\n",
    "Embeddingå±‚ä½¿ç”¨(batch size, max input length)ä½œä¸ºè¾“å…¥ã€‚\n",
    "\n",
    "<img src=\"images/embedding1.png\" style=\"width:700px;height:250px;\">\n",
    "<caption><center> **Figure 4**: Embeddingå±‚. è¿™ä¸ªä¾‹å­å±•ç¤ºäº†ä¸¤ä¸ªè¯­å¥é€šè¿‡embeddingå±‚çš„å‰å‘ä¼ æ’­è¿‡ç¨‹ã€‚ä¸¤ä¸ªè¯­å¥éƒ½ç”¨0å¡«å……åˆ°äº†é•¿åº¦5.æœ€ç»ˆçš„ç»´åº¦æ˜¯`(2,max_len,50)`ï¼Œå› ä¸ºæˆ‘ä»¬ä½¿ç”¨çš„è¯åµŒå…¥æ˜¯50ç»´çš„ã€‚ </center></caption>\n",
    "\n",
    "\n",
    "ç¬¬ä¸€æ­¥å…ˆå°†æ‰€æœ‰è®­ç»ƒçš„å¥å­è½¬æ¢ä¸ºå¯¹åº”çš„ç´¢å¼•åˆ—è¡¨ï¼Œç„¶åå†ç”¨0å¡«å……é•¿åº¦ä¸æ»¡max_lençš„å¥å­ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentences_to_indices(X, word_to_index, max_len):\n",
    "    \n",
    "   \n",
    "    m = X.shape[0]                                \n",
    "    \n",
    "\n",
    "    X_indices = np.zeros((m, max_len))\n",
    "    \n",
    "    for i in range(m):                             \n",
    "        \n",
    "        sentence_words = X[i].lower().split()\n",
    "        \n",
    "        j = 0\n",
    "        \n",
    "        for w in sentence_words:\n",
    "  \n",
    "            X_indices[i, j] = word_to_index[w]\n",
    "        \n",
    "            j = j + 1\n",
    "            \n",
    "    return X_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æŸ¥çœ‹ `sentences_to_indices()` æ•ˆæœ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1 = ['everyday is nice' 'let us play baseball' 'food is ready for you']\n",
      "X1_indices = [[141944. 192973. 260760.      0.      0.]\n",
      " [220870. 374021. 286375.  69714.      0.]\n",
      " [151204. 192973. 302254. 151349. 394475.]]\n"
     ]
    }
   ],
   "source": [
    "X1 = np.array([\"everyday is nice\", \"let us play baseball\", \"food is ready for you\"])\n",
    "X1_indices = sentences_to_indices(X1,word_to_index, max_len = 5)\n",
    "print(\"X1 =\", X1)\n",
    "print(\"X1_indices =\", X1_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åœ¨Kreasä¸­å»ºç«‹`Embedding()` å±‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrained_embedding_layer(word_to_vec_map, word_to_index):\n",
    " \n",
    "    \n",
    "    vocab_len = len(word_to_index) + 1                 \n",
    "    emb_dim = word_to_vec_map[\"cucumber\"].shape[0]      \n",
    "    \n",
    "  \n",
    "    emb_matrix = np.zeros((vocab_len, emb_dim))\n",
    "    \n",
    "\n",
    "    for word, index in word_to_index.items():\n",
    "        emb_matrix[index, :] = word_to_vec_map[word]\n",
    "\n",
    " \n",
    "    embedding_layer = Embedding(vocab_len, emb_dim, trainable=False)\n",
    "\n",
    "\n",
    "    embedding_layer.build((None,))\n",
    "    \n",
    "    \n",
    "    embedding_layer.set_weights([emb_matrix]) # å¯¹åº”åé¢çš„[][][]ä¸‰ä¸ªç»´åº¦\n",
    "    \n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.4 å»ºç«‹æ¨¡å‹\n",
    "\n",
    "å»ºç«‹æ¨¡å‹ï¼Œå°†embeddingå±‚çš„è¾“å‡ºå–‚ç»™LSTMç½‘ç»œ\n",
    "\n",
    "<img src=\"images/model.png\" style=\"width:700px;height:400px;\"> <br>\n",
    "<caption><center> **Figure 5**: ä¸€ä¸ªä¸¤å±‚çš„LSTMåºåˆ—åˆ†ç±»å™¨ </center></caption>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTMModel(input_shape, word_to_vec_map, word_to_index):\n",
    "\n",
    "    sentence_indices = Input(input_shape, dtype='int32')\n",
    "\n",
    "    embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
    "    \n",
    "    embeddings = embedding_layer(sentence_indices)  \n",
    "    \n",
    "    X = LSTM(128, return_sequences=True)(embeddings)\n",
    "   \n",
    "    X = Dropout(0.5)(X)\n",
    "\n",
    "    X = LSTM(128, return_sequences=False)(X)\n",
    "   \n",
    "    X = Dropout(0.5)(X)\n",
    "    \n",
    "    X = Dense(5)(X)\n",
    "    \n",
    "    X = Activation('softmax')(X)\n",
    "    \n",
    "    model = Model(inputs=sentence_indices, outputs=X)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 10, 50)            20000050  \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 10, 128)           91648     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 645       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 20,223,927\n",
      "Trainable params: 223,877\n",
      "Non-trainable params: 20,000,050\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = LSTMModel((maxLen,), word_to_vec_map, word_to_index)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç¼–è¯‘æ¨¡å‹ï¼Œä½¿ç”¨äº¤å‰ç†µæŸå¤±å‡½æ•°ï¼Œå¹¶å°†å‡†ç¡®ç‡ä½œä¸ºè¯„ä¼°æŒ‡æ ‡ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è®­ç»ƒæ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_indices = sentences_to_indices(X_train, word_to_index, maxLen)\n",
    "Y_train_oh = convert_to_one_hot(Y_train, C = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¿­ä»£50æ¬¡ï¼Œæ¯ä»£æ¯ä¸ªæ‰¹æ¬¡çš„æ•°æ®å¤§å°ä¸º32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.1922 - acc: 0.9545\n",
      "Epoch 2/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0972 - acc: 0.9697\n",
      "Epoch 3/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.1390 - acc: 0.9394\n",
      "Epoch 4/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.1015 - acc: 0.9697\n",
      "Epoch 5/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0793 - acc: 0.9773\n",
      "Epoch 6/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0530 - acc: 0.9848\n",
      "Epoch 7/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0362 - acc: 0.9924\n",
      "Epoch 8/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0303 - acc: 0.9924\n",
      "Epoch 9/50\n",
      "132/132 [==============================] - ETA: 0s - loss: 0.0242 - acc: 1.000 - 0s 1ms/step - loss: 0.0279 - acc: 1.0000\n",
      "Epoch 10/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0142 - acc: 1.0000\n",
      "Epoch 11/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0128 - acc: 1.0000\n",
      "Epoch 12/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0145 - acc: 1.0000\n",
      "Epoch 13/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0097 - acc: 1.0000\n",
      "Epoch 14/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0089 - acc: 1.0000\n",
      "Epoch 15/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0074 - acc: 1.0000\n",
      "Epoch 16/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0064 - acc: 1.0000\n",
      "Epoch 17/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0066 - acc: 1.0000\n",
      "Epoch 18/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0064 - acc: 1.0000\n",
      "Epoch 19/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 20/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 21/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 22/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0040 - acc: 1.0000\n",
      "Epoch 23/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0040 - acc: 1.0000\n",
      "Epoch 24/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 25/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 26/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0041 - acc: 1.0000\n",
      "Epoch 27/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 28/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 29/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 30/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 31/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 32/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 33/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 34/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 35/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0046 - acc: 1.0000\n",
      "Epoch 36/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 37/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 38/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 39/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 40/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 41/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 42/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 43/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 44/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 45/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 46/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 47/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 48/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 49/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 50/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0016 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20e02b0c860>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_indices, Y_train_oh, epochs = 50, batch_size = 32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æŸ¥çœ‹æµ‹è¯•é›†å‡†ç¡®ç‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 0s 6ms/step\n",
      "\n",
      "Test accuracy =  0.8392857228006635\n"
     ]
    }
   ],
   "source": [
    "X_test_indices = sentences_to_indices(X_test, word_to_index, max_len = maxLen)\n",
    "Y_test_oh = convert_to_one_hot(Y_test, C = 5)\n",
    "loss, acc = model.evaluate(X_test_indices, Y_test_oh)\n",
    "print()\n",
    "print(\"Test accuracy = \", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æŸ¥çœ‹é”™è¯¯åˆ†ç±»æƒ…å†µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected emoji:ğŸ˜„ prediction: she got me a nice present\tâ¤ï¸\n",
      "Expected emoji:ğŸ˜ prediction: This girl is messing with me\tâ¤ï¸\n",
      "Expected emoji:ğŸ˜ prediction: work is horrible\tğŸ˜„\n",
      "Expected emoji:ğŸ´ prediction: any suggestions for dinner\tğŸ˜„\n",
      "Expected emoji:â¤ï¸ prediction: I love taking breaks\tğŸ˜\n",
      "Expected emoji:ğŸ˜„ prediction: you brighten my day\tâ¤ï¸\n",
      "Expected emoji:ğŸ˜ prediction: she is a bully\tğŸ˜„\n",
      "Expected emoji:ğŸ˜„ prediction: will you be my valentine\tâ¤ï¸\n",
      "Expected emoji:ğŸ˜ prediction: go away\tâš¾\n"
     ]
    }
   ],
   "source": [
    "C = 5\n",
    "y_test_oh = np.eye(C)[Y_test.reshape(-1)]\n",
    "X_test_indices = sentences_to_indices(X_test, word_to_index, maxLen)\n",
    "pred = model.predict(X_test_indices)\n",
    "for i in range(len(X_test)):\n",
    "    x = X_test_indices\n",
    "    num = np.argmax(pred[i])\n",
    "    if(num != Y_test[i]):\n",
    "        print('Expected emoji:'+ label_to_emoji(Y_test[i]) + ' prediction: '+ X_test[i] + label_to_emoji(num).strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å°è¯•è‡ªå·±çš„æµ‹è¯•è¯­å¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am hungry ğŸ´\n"
     ]
    }
   ],
   "source": [
    "inputSentence = \"I am hungry\"\n",
    "x_test = np.array([inputSentence])\n",
    "X_test_indices = sentences_to_indices(x_test, word_to_index, maxLen)\n",
    "print(x_test[0] +' '+  label_to_emoji(np.argmax(model.predict(X_test_indices))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - ä¿å­˜æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - åŠ è½½æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('model/my_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å°è¯•è‡ªå·±çš„æµ‹è¯•è¯­å¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am very glad to see you ğŸ˜„\n"
     ]
    }
   ],
   "source": [
    "inputSentence = \"I am very glad to see you\"\n",
    "x_test = np.array([inputSentence])\n",
    "X_test_indices = sentences_to_indices(x_test, word_to_index, maxLen)\n",
    "print(x_test[0] +' '+  label_to_emoji(np.argmax(model.predict(X_test_indices))))"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "nlp-sequence-models",
   "graded_item_id": "RNnEs",
   "launcher_item_id": "acNYU"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
